<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Felipe Nuti</title>

    <meta name="author" content="Felipe Nuti">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Felipe Nuti
                </p>

                <p>
                  I am a Quantitative Researcher at <a href="https://www.citadelsecurities.com/">Citadel Securities</a>, working on modeling for Systematic Fixed Income, Commodities and Currencies (FICC) strategies.
                </p>
                <p>
                  Before that, I did my undergraduate degree in Mathematics and Computer Science at the <a href="https://www.ox.ac.uk/">University of Oxford</a>, where I studied stochastic analysis and maching learning, and did research at the <a href="https://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a> under <a href="https://www.robots.ox.ac.uk/~frtim/">Tim Franzmeyer</a> and <a href="https://www.robots.ox.ac.uk/~joao/">Jo達o Henriques</a>.
                </p>
                <p>
                  During my degree, I interned at <a href="https://www.citadelsecurities.com/">Citadel Securities</a> as a Quantitative Researcher in Systematic FX. Before that, I did an internship on Causal Inference and Machine Learning at <a href="https://www.quantco.com/">QuantCo Z端rich</a>.
                </p>

                <h3>Academic research</h3>
                <p>
                  My academic research has focused on quantifying differences between generative models, especially in safety settings.
                </p>
                <p>
                  We recently proposed a <a href="https://arxiv.org/abs/2506.23423">method for measuring the contribution of fine-tuning to individual LLM responses</a>, and quantitatively showed that strong jailbreak attacks attenuate this contribution.
                </p>
                <p>
                  In 2023, we also proposed the <a href="https://arxiv.org/abs/2306.01804">first method for extracting reward functions from two diffusion models</a>, which was able to, for example, extract a harmful content classifier by comparing an image generation diffusion model with safety guardrails to one without.
                </p>

                <p style="text-align:center">
                  <a href="mailto:<firstname><lastname>1182@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=BLMdYoEAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/felipe-nuti/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/NutiFelipe">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/FelipeNuti">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/FelipeNuti.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/FelipeNuti_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/tuco_plot.png' width="160" style="border: 2px solid #d3d3d3;">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/forum?id=yxoxw0IUTR">
          <span class="papertitle">TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs</span>
        </a>
        <br>
        <b>Felipe Nuti</b>,
        Tim Franzmeyer,
        Jo達o F. Henriques
        <br>
        <em>ICML</em>, 2025
        <br>
        <a href="https://openreview.net/forum?id=yxoxw0IUTR">OpenReview</a>
        /
        <a href="https://arxiv.org/abs/2506.23423">arXiv</a>
        /
        <a href="https://github.com/FelipeNuti/tuning-contribution">code</a>
        <p></p>
        <p>
        A method for quantifying how much fine-tuning contributes to an LLM's response using intermediate hidden states. 
        We use it to quantitatively demonstrate that jailbreak attacks attenuate the effect of fine-tuning, and the attenuation is stronger the more powerful the attack.
        </p>
      </td>
    </tr>
            
    <tr onmouseout="rrf_stop()" onmouseover="rrf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/rrf_maze.png' width="160" style="border: 2px solid #d3d3d3;">
        </div>
        <script type="text/javascript">
          function recon_start() {
            document.getElementById('recon_image').style.opacity = "1";
          }

          function recon_stop() {
            document.getElementById('recon_image').style.opacity = "0";
          }
          recon_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://nips.cc/virtual/2023/poster/71865">
          <span class="papertitle">Extracting Reward Functions from Diffusion Models</span>
        </a>
        <br>
        <b>Felipe Nuti*</b>,
        <a href="https://www.robots.ox.ac.uk/~frtim/">Tim Franzmeyer*</a>,
        <a href="https://www.robots.ox.ac.uk/~joao/">Jo達o Henriques</a>
        <br>
        <em>NeurIPS</em>, 2023
        <br>
        <a href="https://nips.cc/virtual/2023/poster/71865">conference page</a>
        /
        <a href="https://arxiv.org/abs/2306.01804">arXiv</a>
        <p></p>
        <p>
        A method for quantifying differences in preferences between any two diffusion models.
        </p>
      </t
